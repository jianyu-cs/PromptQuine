Metadata-Version: 2.2
Name: PromptQuine
Version: 0.1.0
Summary: Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective
Home-page: https://github.com/jianyu-cs/PromptQuine/
Author: Jianyu Wang, Zhiqiang Hu, Lidong Bing
License: MIT
Keywords: Open-Ended Prompt Evolution
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: bert_score==0.3.13
Requires-Dist: click==8.2.1
Requires-Dist: hydra-core==1.3.2
Requires-Dist: numpy==1.26.0
Requires-Dist: omegaconf==2.3.0
Requires-Dist: openai==1.107.3
Requires-Dist: pandas==2.3.2
Requires-Dist: sacrebleu==2.5.1
Requires-Dist: setuptools==75.8.0
Requires-Dist: tiktoken==0.11.0
Requires-Dist: tqdm==4.67.1
Requires-Dist: transformers==4.52.0
Requires-Dist: vllm==0.6.6
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# PromptQuine ðŸ¦Ž

This repo contains the code of the discrete prompt optimization framework described in the paper \
**Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective** \
ICML 2025

## Getting Started
> ðŸ§¬ A novel prompt design paradigm, resembling the open-ended nature of biological evolution ðŸ¦•.

![Open-Ended Prompt Evolution for LLM Self-improvement](PromptQuine-repo.png)

* Conventional wisdom of LLM prompting suggests that well-cafted natural language instructions, combined with a few well-tuned demonstrations work best (e.g., see [this](https://proceedings.neurips.cc/paper_files/paper/2024/file/6b031defd145b02bed031093d8797bb3-Paper-Conference.pdf)) for current LLM prompting (often, have undergone significant alignment efforts).
* In our paper, we present a *counterintuitive result*: pruning random demonstrations into seemingly incoherent ''gibberish'' (both syntactically and semantically strange) can surprisingly improve task performance.
* Surprisingly, it often achieves near state-of-the-art prompt optimization results.
* This suggests that pruning original ICL prompts could be an elegant alternative towards prompt optimization or any other ICL stablization algorithms (e.g., via retrieving semantically similar examples).
* Nevertheless, **neither** traditional attribution methods **nor** prompt compression methods show effectiveness in our formulation.
* We thus propose an evolutionary search framework, namely **PromptQuine**, that automatically evolves decent pruning strategies over successive generations.
* Empirical success over multiple tasks and models has demonstrated the effectiveness of our framework.

## Author Message
We release **PromptQuine** as well as **TAPruning and SAHCPruning** for follow-up studies. We hope our work can serve as useful tools for further mechanistic studies of in-context learning and overall LLM prompt sensitivity.

## Setting Up
Note that although it's desirable to use vLLM v1 for the inference. By now, vLLM hasn't enabled the features of <logits-processor> in their up-to-date release. Thus, please install vllm~0.9x in order to support our classification task settings. 

Install our core modules with
> pip install -e .

## Usage


## Acknowledgment
We adapt the [code implementation in RLPrompt](https://github.com/mingkaid/rl-prompt/tree/main) for its user-friendly implementation in classification and style transfer tasks.

