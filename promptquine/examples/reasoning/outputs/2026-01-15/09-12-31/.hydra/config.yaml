data:
  dataset: mawps
  dataset_seed: null
  base_path: ./data
  max_size: 100
prompt:
  prompt: ''
  is_pruned_prompt: true
model:
  name: meta-llama/Meta-Llama-3-8B-Instruct
  ICL_shots: 1
  ICL_index: 2
  num_devices: 1
pruning:
  algorithm: PromptQuine
  fix_prune_order: true
  pruning_order_seed: 0
  TAPruning_threshold: 0.96
prompt_quine:
  initialize_duplicate: true
  min_prompt_length: 15
  max_num_prompts: 10000
  algorithm_mode: GGA
  population_size: 30
  reproduction_size: 50
  top_percent_rerank: 10
  test_all_elites_for_debug: false
  successive_halving: true
