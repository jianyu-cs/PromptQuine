- model.name=meta-llama/Meta-Llama-3-8B-Instruct
- model.inference_engine=vLLM
- pruning.algorithm=PromptQuine
- pruning.reward_driven=True
- prompt_quine.algorithm_mode=SSGA
