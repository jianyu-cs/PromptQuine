data:
  mode: reduce
  dataset: piqa
  dataset_seed: 0
  num_shots: 16
  split: false
  split_seed: 0
  is_random_verbalizers: false
prompt:
  prompt: ''
  is_pruned_prompt: true
model:
  name: meta-llama/Meta-Llama-3-8B-Instruct
  ICL_shots: 1
  ICL_index: 3
  num_devices: 1
  inference_engine: vLLM
pruning:
  algorithm: PromptQuine
  fix_prune_order: true
  pruning_order_seed: 0
  TAPruning_threshold: 0.96
  reward_driven: true
prompt_quine:
  initialize_duplicate: true
  min_prompt_length: 15
  max_num_prompts: 10000
  algorithm_mode: GGA
  population_size: 30
  reproduction_size: 50
  top_percent_rerank: 10
  test_all_elites_for_debug: false
