CUDA_VISIBLE_DEVICES=0 python prompt_eval.py \
  model.name="meta-llama/Meta-Llama-3-8B-Instruct" \
  model.inference_engine="vLLM" \
  model.num_devices=1 \
  data.dataset=subj \
  pruning.algorithm="PromptQuine" \
  pruning.reward_driven=True \
  prompt_quine.algorithm_mode=GGA \
  prompt_quine.initialize_duplicate=True \
  model.ICL_index=0 \
  model.ICL_shots=1 \
  data.dataset_seed=0 \

CUDA_VISIBLE_DEVICES=0 python prompt_eval.py \
  model.name="meta-llama/Meta-Llama-3-8B-Instruct" \
  model.inference_engine="vLLM" \
  model.num_devices=1 \
  data.dataset=subj \
  pruning.algorithm="PromptQuine" \
  pruning.reward_driven=True \
  prompt_quine.algorithm_mode=GGA \
  prompt_quine.initialize_duplicate=True \
  model.ICL_index=1 \
  model.ICL_shots=1 \
  data.dataset_seed=0

CUDA_VISIBLE_DEVICES=0 python prompt_eval.py \
  model.name="meta-llama/Meta-Llama-3-8B-Instruct" \
  model.inference_engine="vLLM" \
  model.num_devices=1 \
  data.dataset=snli \
  pruning.algorithm="PromptQuine" \
  pruning.reward_driven=True \
  prompt_quine.algorithm_mode=GGA \
  prompt_quine.initialize_duplicate=True \
  model.ICL_index=1 \
  model.ICL_shots=1 \
  data.dataset_seed=0

CUDA_VISIBLE_DEVICES=0 python prompt_eval.py \
  model.name="meta-llama/Meta-Llama-3-8B-Instruct" \
  model.inference_engine="vLLM" \
  model.num_devices=1 \
  data.dataset=snli \
  pruning.algorithm="PromptQuine" \
  pruning.reward_driven=True \
  prompt_quine.algorithm_mode=GGA \
  prompt_quine.initialize_duplicate=True \
  model.ICL_index=0 \
  model.ICL_shots=1 \
  data.dataset_seed=0

CUDA_VISIBLE_DEVICES=0 python prompt_eval.py \
  model.name="FacebookAI/roberta-large" \
  model.inference_engine="HF" \
  model.num_devices=1 \
  data.dataset=snli \
  pruning.algorithm="PromptQuine" \
  pruning.reward_driven=True \
  prompt_quine.algorithm_mode=GGA \
  prompt_quine.initialize_duplicate=True \
  model.ICL_index=0 \
  model.ICL_shots=1 \
  data.dataset_seed=0

CUDA_VISIBLE_DEVICES=0 python prompt_eval.py \
  model.name="FacebookAI/roberta-large" \
  model.inference_engine="HF" \
  model.num_devices=1 \
  data.dataset=snli \
  pruning.algorithm="PromptQuine" \
  pruning.reward_driven=True \
  prompt_quine.algorithm_mode=GGA \
  prompt_quine.initialize_duplicate=True \
  model.ICL_index=1 \
  model.ICL_shots=1 \
  data.dataset_seed=0

CUDA_VISIBLE_DEVICES=0 python prompt_eval.py \
  model.name="FacebookAI/roberta-large" \
  model.inference_engine="HF" \
  model.num_devices=1 \
  data.dataset=subj \
  pruning.algorithm="PromptQuine" \
  pruning.reward_driven=True \
  prompt_quine.algorithm_mode=GGA \
  prompt_quine.initialize_duplicate=True \
  model.ICL_index=0 \
  model.ICL_shots=1 \
  data.dataset_seed=0

CUDA_VISIBLE_DEVICES=0 python prompt_eval.py \
  model.name="FacebookAI/roberta-large" \
  model.inference_engine="HF" \
  model.num_devices=1 \
  data.dataset=subj \
  pruning.algorithm="PromptQuine" \
  pruning.reward_driven=True \
  prompt_quine.algorithm_mode=GGA \
  prompt_quine.initialize_duplicate=True \
  model.ICL_index=1 \
  model.ICL_shots=1 \
  data.dataset_seed=0

